
R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Workspace loaded from ~/.RData]

> ###########################################################
> # working directory
> ###########################################################
> getwd()
[1] "/home/iss-user"
> setwd("/home/iss-user/Desktop/workshop/")
> getwd()
[1] "/home/iss-user/Desktop/workshop"
> # Preparing the Data - MNIST hand writing digits
> library(keras)
> mnist <- dataset_mnist()
> x_train <- mnist$train$x
> y_train <- mnist$train$y
> x_test <- mnist$test$x
> y_test <- mnist$test$y
> # reshape
> x_train <- array_reshape(x_train, c(nrow(x_train), 784))
> x_test <- array_reshape(x_test, c(nrow(x_test), 784))
> # rescale
> x_train <- x_train / 255
> x_test <- x_test / 255
> y_train <- to_categorical(y_train, 10)
> y_test <- to_categorical(y_test, 10)
> # Defining the Model
> model <- keras_model_sequential()
> model %>% 
+   layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>% 
+   layer_dropout(rate = 0.4) %>% 
+   layer_dense(units = 128, activation = 'relu') %>%
+   layer_dropout(rate = 0.3) %>%
+   layer_dense(units = 10, activation = 'softmax')
> summary(model)
________________________________________________________________________
Layer (type)                    Output Shape                 Param #    
========================================================================
dense_1 (Dense)                 (None, 256)                  200960     
________________________________________________________________________
dropout_1 (Dropout)             (None, 256)                  0          
________________________________________________________________________
dense_2 (Dense)                 (None, 128)                  32896      
________________________________________________________________________
dropout_2 (Dropout)             (None, 128)                  0          
________________________________________________________________________
dense_3 (Dense)                 (None, 10)                   1290       
========================================================================
Total params: 235,146
Trainable params: 235,146
Non-trainable params: 0
________________________________________________________________________
> model %>% compile(
+   loss = 'categorical_crossentropy',
+   optimizer = optimizer_rmsprop(),
+   metrics = c('accuracy')
+ )
> # Training and Evaluation
> history <- model %>% fit(
+   x_train, y_train, 
+ #  epochs = 30, batch_size = 128, 
+   epochs = 100, batch_size = 128, 
+   validation_split = 0.2
+ )
Train on 48000 samples, validate on 12000 samples
Epoch 1/100
48000/48000 [==============================] - 13s 266us/step - loss: 0.4304 - acc: 0.8692 - val_loss: 0.1553 - val_acc: 0.9546
Epoch 2/100
48000/48000 [==============================] - 4s 81us/step - loss: 0.2047 - acc: 0.9400 - val_loss: 0.1236 - val_acc: 0.9641
Epoch 3/100
48000/48000 [==============================] - 7s 145us/step - loss: 0.1562 - acc: 0.9526 - val_loss: 0.1007 - val_acc: 0.9722
Epoch 4/100
48000/48000 [==============================] - 7s 150us/step - loss: 0.1313 - acc: 0.9609 - val_loss: 0.0988 - val_acc: 0.9725
Epoch 5/100
48000/48000 [==============================] - 4s 79us/step - loss: 0.1157 - acc: 0.9662 - val_loss: 0.0892 - val_acc: 0.9772
Epoch 6/100
48000/48000 [==============================] - 7s 147us/step - loss: 0.1017 - acc: 0.9698 - val_loss: 0.0957 - val_acc: 0.9736
Epoch 7/100
48000/48000 [==============================] - 6s 117us/step - loss: 0.0983 - acc: 0.9701 - val_loss: 0.0895 - val_acc: 0.9771
Epoch 8/100
48000/48000 [==============================] - 5s 105us/step - loss: 0.0893 - acc: 0.9738 - val_loss: 0.0860 - val_acc: 0.9774
Epoch 9/100
48000/48000 [==============================] - 5s 111us/step - loss: 0.0849 - acc: 0.9749 - val_loss: 0.0875 - val_acc: 0.9775
Epoch 10/100
48000/48000 [==============================] - 7s 138us/step - loss: 0.0819 - acc: 0.9762 - val_loss: 0.0916 - val_acc: 0.9773
Epoch 11/100
48000/48000 [==============================] - 6s 118us/step - loss: 0.0775 - acc: 0.9776 - val_loss: 0.0906 - val_acc: 0.9789
Epoch 12/100
48000/48000 [==============================] - 8s 173us/step - loss: 0.0760 - acc: 0.9776 - val_loss: 0.0910 - val_acc: 0.9772
Epoch 13/100
48000/48000 [==============================] - 6s 116us/step - loss: 0.0720 - acc: 0.9791 - val_loss: 0.0886 - val_acc: 0.9792
Epoch 14/100
48000/48000 [==============================] - 7s 153us/step - loss: 0.0682 - acc: 0.9802 - val_loss: 0.0918 - val_acc: 0.9789
Epoch 15/100
48000/48000 [==============================] - 6s 134us/step - loss: 0.0685 - acc: 0.9807 - val_loss: 0.0936 - val_acc: 0.9790
Epoch 16/100
48000/48000 [==============================] - 7s 145us/step - loss: 0.0678 - acc: 0.9810 - val_loss: 0.0867 - val_acc: 0.9797
Epoch 17/100
48000/48000 [==============================] - 6s 128us/step - loss: 0.0647 - acc: 0.9812 - val_loss: 0.0923 - val_acc: 0.9795
Epoch 18/100
48000/48000 [==============================] - 8s 159us/step - loss: 0.0628 - acc: 0.9825 - val_loss: 0.0941 - val_acc: 0.9803
Epoch 19/100
48000/48000 [==============================] - 5s 101us/step - loss: 0.0586 - acc: 0.9834 - val_loss: 0.0990 - val_acc: 0.9792
Epoch 20/100
48000/48000 [==============================] - 8s 158us/step - loss: 0.0587 - acc: 0.9833 - val_loss: 0.0898 - val_acc: 0.9803
Epoch 21/100
48000/48000 [==============================] - 8s 169us/step - loss: 0.0586 - acc: 0.9840 - val_loss: 0.0951 - val_acc: 0.9802
Epoch 22/100
48000/48000 [==============================] - 8s 159us/step - loss: 0.0567 - acc: 0.9844 - val_loss: 0.0924 - val_acc: 0.9807
Epoch 23/100
48000/48000 [==============================] - 8s 161us/step - loss: 0.0581 - acc: 0.9844 - val_loss: 0.0984 - val_acc: 0.9794
Epoch 24/100
48000/48000 [==============================] - 8s 163us/step - loss: 0.0554 - acc: 0.9855 - val_loss: 0.0953 - val_acc: 0.9793
Epoch 25/100
48000/48000 [==============================] - 8s 170us/step - loss: 0.0544 - acc: 0.9857 - val_loss: 0.0991 - val_acc: 0.9800
Epoch 26/100
48000/48000 [==============================] - 9s 183us/step - loss: 0.0562 - acc: 0.9850 - val_loss: 0.0968 - val_acc: 0.9805
Epoch 27/100
48000/48000 [==============================] - 8s 166us/step - loss: 0.0539 - acc: 0.9856 - val_loss: 0.1008 - val_acc: 0.9798
Epoch 28/100
48000/48000 [==============================] - 9s 192us/step - loss: 0.0570 - acc: 0.9846 - val_loss: 0.0997 - val_acc: 0.9807
Epoch 29/100
48000/48000 [==============================] - 8s 163us/step - loss: 0.0524 - acc: 0.9859 - val_loss: 0.1024 - val_acc: 0.9809
Epoch 30/100
48000/48000 [==============================] - 9s 183us/step - loss: 0.0528 - acc: 0.9854 - val_loss: 0.1021 - val_acc: 0.9803
Epoch 31/100
48000/48000 [==============================] - 8s 162us/step - loss: 0.0498 - acc: 0.9868 - val_loss: 0.1008 - val_acc: 0.9811
Epoch 32/100
48000/48000 [==============================] - 8s 174us/step - loss: 0.0510 - acc: 0.9864 - val_loss: 0.0978 - val_acc: 0.9820
Epoch 33/100
48000/48000 [==============================] - 9s 179us/step - loss: 0.0483 - acc: 0.9872 - val_loss: 0.1102 - val_acc: 0.9802
Epoch 34/100
48000/48000 [==============================] - 8s 172us/step - loss: 0.0503 - acc: 0.9868 - val_loss: 0.1025 - val_acc: 0.9812
Epoch 35/100
48000/48000 [==============================] - 9s 178us/step - loss: 0.0501 - acc: 0.9871 - val_loss: 0.1073 - val_acc: 0.9807
Epoch 36/100
48000/48000 [==============================] - 8s 157us/step - loss: 0.0499 - acc: 0.9873 - val_loss: 0.1038 - val_acc: 0.9823
Epoch 37/100
48000/48000 [==============================] - 8s 172us/step - loss: 0.0498 - acc: 0.9867 - val_loss: 0.1083 - val_acc: 0.9807
Epoch 38/100
48000/48000 [==============================] - 8s 170us/step - loss: 0.0478 - acc: 0.9878 - val_loss: 0.1105 - val_acc: 0.9811
Epoch 39/100
48000/48000 [==============================] - 6s 134us/step - loss: 0.0484 - acc: 0.9876 - val_loss: 0.1105 - val_acc: 0.9808
Epoch 40/100
48000/48000 [==============================] - 5s 95us/step - loss: 0.0463 - acc: 0.9880 - val_loss: 0.1080 - val_acc: 0.9818
Epoch 41/100
48000/48000 [==============================] - 5s 95us/step - loss: 0.0462 - acc: 0.9882 - val_loss: 0.1088 - val_acc: 0.9808
Epoch 42/100
48000/48000 [==============================] - 4s 90us/step - loss: 0.0471 - acc: 0.9884 - val_loss: 0.1174 - val_acc: 0.9810
Epoch 43/100
48000/48000 [==============================] - 4s 93us/step - loss: 0.0487 - acc: 0.9877 - val_loss: 0.1129 - val_acc: 0.9824
Epoch 44/100
48000/48000 [==============================] - 7s 142us/step - loss: 0.0462 - acc: 0.9881 - val_loss: 0.1066 - val_acc: 0.9826
Epoch 45/100
48000/48000 [==============================] - 7s 140us/step - loss: 0.0458 - acc: 0.9881 - val_loss: 0.1192 - val_acc: 0.9804
Epoch 46/100
48000/48000 [==============================] - 7s 145us/step - loss: 0.0418 - acc: 0.9891 - val_loss: 0.1168 - val_acc: 0.9810
Epoch 47/100
48000/48000 [==============================] - 6s 135us/step - loss: 0.0446 - acc: 0.9895 - val_loss: 0.1218 - val_acc: 0.9806
Epoch 48/100
48000/48000 [==============================] - 7s 150us/step - loss: 0.0453 - acc: 0.9889 - val_loss: 0.1236 - val_acc: 0.9800
Epoch 49/100
48000/48000 [==============================] - 6s 123us/step - loss: 0.0422 - acc: 0.9895 - val_loss: 0.1216 - val_acc: 0.9819
Epoch 50/100
48000/48000 [==============================] - 7s 143us/step - loss: 0.0433 - acc: 0.9890 - val_loss: 0.1208 - val_acc: 0.9807
Epoch 51/100
48000/48000 [==============================] - 6s 133us/step - loss: 0.0413 - acc: 0.9897 - val_loss: 0.1232 - val_acc: 0.9802
Epoch 52/100
48000/48000 [==============================] - 7s 139us/step - loss: 0.0449 - acc: 0.9892 - val_loss: 0.1242 - val_acc: 0.9815
Epoch 53/100
48000/48000 [==============================] - 6s 121us/step - loss: 0.0445 - acc: 0.9890 - val_loss: 0.1185 - val_acc: 0.9821
Epoch 54/100
48000/48000 [==============================] - 7s 140us/step - loss: 0.0446 - acc: 0.9891 - val_loss: 0.1199 - val_acc: 0.9815
Epoch 55/100
48000/48000 [==============================] - 6s 117us/step - loss: 0.0431 - acc: 0.9890 - val_loss: 0.1212 - val_acc: 0.9812
Epoch 56/100
48000/48000 [==============================] - 7s 152us/step - loss: 0.0454 - acc: 0.9892 - val_loss: 0.1264 - val_acc: 0.9803
Epoch 57/100
48000/48000 [==============================] - 5s 109us/step - loss: 0.0418 - acc: 0.9898 - val_loss: 0.1265 - val_acc: 0.9820
Epoch 58/100
48000/48000 [==============================] - 7s 153us/step - loss: 0.0469 - acc: 0.9894 - val_loss: 0.1179 - val_acc: 0.9824
Epoch 59/100
48000/48000 [==============================] - 6s 119us/step - loss: 0.0419 - acc: 0.9895 - val_loss: 0.1299 - val_acc: 0.9806
Epoch 60/100
48000/48000 [==============================] - 7s 147us/step - loss: 0.0426 - acc: 0.9900 - val_loss: 0.1199 - val_acc: 0.9807
Epoch 61/100
48000/48000 [==============================] - 5s 112us/step - loss: 0.0490 - acc: 0.9894 - val_loss: 0.1183 - val_acc: 0.9827
Epoch 62/100
48000/48000 [==============================] - 7s 150us/step - loss: 0.0465 - acc: 0.9899 - val_loss: 0.1307 - val_acc: 0.9812
Epoch 63/100
48000/48000 [==============================] - 5s 112us/step - loss: 0.0382 - acc: 0.9910 - val_loss: 0.1262 - val_acc: 0.9806
Epoch 64/100
48000/48000 [==============================] - 7s 146us/step - loss: 0.0450 - acc: 0.9900 - val_loss: 0.1226 - val_acc: 0.9814
Epoch 65/100
48000/48000 [==============================] - 6s 133us/step - loss: 0.0453 - acc: 0.9897 - val_loss: 0.1302 - val_acc: 0.9816
Epoch 66/100
48000/48000 [==============================] - 8s 157us/step - loss: 0.0419 - acc: 0.9906 - val_loss: 0.1296 - val_acc: 0.9821
Epoch 67/100
48000/48000 [==============================] - 6s 135us/step - loss: 0.0457 - acc: 0.9896 - val_loss: 0.1299 - val_acc: 0.9805
Epoch 68/100
48000/48000 [==============================] - 7s 142us/step - loss: 0.0411 - acc: 0.9906 - val_loss: 0.1284 - val_acc: 0.9825
Epoch 69/100
48000/48000 [==============================] - 7s 139us/step - loss: 0.0446 - acc: 0.9897 - val_loss: 0.1307 - val_acc: 0.9804
Epoch 70/100
48000/48000 [==============================] - 6s 123us/step - loss: 0.0404 - acc: 0.9910 - val_loss: 0.1387 - val_acc: 0.9789
Epoch 71/100
48000/48000 [==============================] - 7s 152us/step - loss: 0.0414 - acc: 0.9900 - val_loss: 0.1292 - val_acc: 0.9807
Epoch 72/100
48000/48000 [==============================] - 6s 132us/step - loss: 0.0417 - acc: 0.9904 - val_loss: 0.1314 - val_acc: 0.9808
Epoch 73/100
48000/48000 [==============================] - 6s 133us/step - loss: 0.0401 - acc: 0.9908 - val_loss: 0.1264 - val_acc: 0.9824
Epoch 74/100
48000/48000 [==============================] - 7s 139us/step - loss: 0.0413 - acc: 0.9909 - val_loss: 0.1349 - val_acc: 0.9817
Epoch 75/100
48000/48000 [==============================] - 6s 127us/step - loss: 0.0435 - acc: 0.9902 - val_loss: 0.1247 - val_acc: 0.9822
Epoch 76/100
48000/48000 [==============================] - 7s 143us/step - loss: 0.0408 - acc: 0.9909 - val_loss: 0.1382 - val_acc: 0.9806
Epoch 77/100
48000/48000 [==============================] - 6s 118us/step - loss: 0.0419 - acc: 0.9906 - val_loss: 0.1234 - val_acc: 0.9811
Epoch 78/100
48000/48000 [==============================] - 7s 139us/step - loss: 0.0419 - acc: 0.9909 - val_loss: 0.1349 - val_acc: 0.9810
Epoch 79/100
48000/48000 [==============================] - 6s 125us/step - loss: 0.0398 - acc: 0.9914 - val_loss: 0.1309 - val_acc: 0.9827
Epoch 80/100
48000/48000 [==============================] - 6s 135us/step - loss: 0.0366 - acc: 0.9917 - val_loss: 0.1372 - val_acc: 0.9823
Epoch 81/100
48000/48000 [==============================] - 6s 129us/step - loss: 0.0391 - acc: 0.9912 - val_loss: 0.1413 - val_acc: 0.9806
Epoch 82/100
48000/48000 [==============================] - 6s 120us/step - loss: 0.0390 - acc: 0.9912 - val_loss: 0.1492 - val_acc: 0.9809
Epoch 83/100
48000/48000 [==============================] - 7s 137us/step - loss: 0.0419 - acc: 0.9908 - val_loss: 0.1388 - val_acc: 0.9808
Epoch 84/100
48000/48000 [==============================] - 6s 123us/step - loss: 0.0444 - acc: 0.9908 - val_loss: 0.1415 - val_acc: 0.9817
Epoch 85/100
48000/48000 [==============================] - 7s 137us/step - loss: 0.0377 - acc: 0.9915 - val_loss: 0.1304 - val_acc: 0.9829
Epoch 86/100
48000/48000 [==============================] - 6s 116us/step - loss: 0.0409 - acc: 0.9911 - val_loss: 0.1282 - val_acc: 0.9822
Epoch 87/100
48000/48000 [==============================] - 7s 138us/step - loss: 0.0394 - acc: 0.9912 - val_loss: 0.1293 - val_acc: 0.9815
Epoch 88/100
48000/48000 [==============================] - 7s 144us/step - loss: 0.0428 - acc: 0.9908 - val_loss: 0.1248 - val_acc: 0.9828
Epoch 89/100
48000/48000 [==============================] - 8s 160us/step - loss: 0.0381 - acc: 0.9916 - val_loss: 0.1389 - val_acc: 0.9823
Epoch 90/100
48000/48000 [==============================] - 8s 158us/step - loss: 0.0425 - acc: 0.9908 - val_loss: 0.1400 - val_acc: 0.9812
Epoch 91/100
48000/48000 [==============================] - 8s 157us/step - loss: 0.0424 - acc: 0.9908 - val_loss: 0.1351 - val_acc: 0.9831
Epoch 92/100
48000/48000 [==============================] - 8s 175us/step - loss: 0.0413 - acc: 0.9911 - val_loss: 0.1370 - val_acc: 0.9820
Epoch 93/100
48000/48000 [==============================] - 7s 151us/step - loss: 0.0416 - acc: 0.9913 - val_loss: 0.1466 - val_acc: 0.9805
Epoch 94/100
48000/48000 [==============================] - 8s 175us/step - loss: 0.0406 - acc: 0.9910 - val_loss: 0.1427 - val_acc: 0.9807
Epoch 95/100
48000/48000 [==============================] - 8s 176us/step - loss: 0.0451 - acc: 0.9913 - val_loss: 0.1445 - val_acc: 0.9809
Epoch 96/100
48000/48000 [==============================] - 8s 159us/step - loss: 0.0390 - acc: 0.9916 - val_loss: 0.1422 - val_acc: 0.9819
Epoch 97/100
48000/48000 [==============================] - 8s 173us/step - loss: 0.0416 - acc: 0.9916 - val_loss: 0.1399 - val_acc: 0.9810
Epoch 98/100
48000/48000 [==============================] - 8s 166us/step - loss: 0.0398 - acc: 0.9912 - val_loss: 0.1453 - val_acc: 0.9804
Epoch 99/100
48000/48000 [==============================] - 8s 168us/step - loss: 0.0445 - acc: 0.9914 - val_loss: 0.1353 - val_acc: 0.9808
Epoch 100/100
48000/48000 [==============================] - 8s 166us/step - loss: 0.0378 - acc: 0.9916 - val_loss: 0.1416 - val_acc: 0.9810
> plot(history)
> # Evaluate the modelâ€™s performance on the test data
> model %>% evaluate(x_test, y_test)
10000/10000 [==============================] - 1s 135us/step
$loss
[1] 0.145084

$acc
[1] 0.9831

